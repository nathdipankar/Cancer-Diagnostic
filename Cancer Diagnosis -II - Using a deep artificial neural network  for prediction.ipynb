{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosis of cancer\n",
    "\n",
    "In this post I will describe how to build a deep neural network that can predict whether a tumor is malignant or benign. In the earlier [post](https://nathdip.github.io/cancer%20diagnosis%20I.html), we have looked into how we can use a linear classifier and just two features to classify the different tumors. However with the large number of features at our disposal a logical way to get the best classification is to train a neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing a deep neural network.\n",
    "\n",
    "Neural networks consists of network of interconnected nodes or neurons as it is inspired by connection among neurons in the brain. The various features form the input layer of neuron. There is also another set of neuron(s) which form the output layer. Connecting the input layer and the output layer are the hidden layer. Depending upon the application we might have several such hidden layers. Deep neural networks consists of several such hidden layers. \n",
    "\n",
    "In this particular case we will have a neural network which has an input layer of size number of features. Let us have a look at our data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>843786</td>\n",
       "      <td>M</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>844359</td>\n",
       "      <td>M</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84458202</td>\n",
       "      <td>M</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>844981</td>\n",
       "      <td>M</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>84501001</td>\n",
       "      <td>M</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "5    843786         M        12.45         15.70           82.57      477.1   \n",
       "6    844359         M        18.25         19.98          119.60     1040.0   \n",
       "7  84458202         M        13.71         20.83           90.20      577.9   \n",
       "8    844981         M        13.00         21.82           87.50      519.8   \n",
       "9  84501001         M        12.46         24.04           83.97      475.9   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760         0.30010              0.14710   \n",
       "1          0.08474           0.07864         0.08690              0.07017   \n",
       "2          0.10960           0.15990         0.19740              0.12790   \n",
       "3          0.14250           0.28390         0.24140              0.10520   \n",
       "4          0.10030           0.13280         0.19800              0.10430   \n",
       "5          0.12780           0.17000         0.15780              0.08089   \n",
       "6          0.09463           0.10900         0.11270              0.07400   \n",
       "7          0.11890           0.16450         0.09366              0.05985   \n",
       "8          0.12730           0.19320         0.18590              0.09353   \n",
       "9          0.11860           0.23960         0.22730              0.08543   \n",
       "\n",
       "      ...       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0     ...               17.33           184.60      2019.0            0.1622   \n",
       "1     ...               23.41           158.80      1956.0            0.1238   \n",
       "2     ...               25.53           152.50      1709.0            0.1444   \n",
       "3     ...               26.50            98.87       567.7            0.2098   \n",
       "4     ...               16.67           152.20      1575.0            0.1374   \n",
       "5     ...               23.75           103.40       741.6            0.1791   \n",
       "6     ...               27.66           153.20      1606.0            0.1442   \n",
       "7     ...               28.14           110.60       897.0            0.1654   \n",
       "8     ...               30.73           106.20       739.3            0.1703   \n",
       "9     ...               40.68            97.65       711.4            0.1853   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "5             0.5249           0.5355                0.1741          0.3985   \n",
       "6             0.2576           0.3784                0.1932          0.3063   \n",
       "7             0.3682           0.2678                0.1556          0.3196   \n",
       "8             0.5401           0.5390                0.2060          0.4378   \n",
       "9             1.0580           1.1050                0.2210          0.4366   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "5                  0.12440          NaN  \n",
       "6                  0.08368          NaN  \n",
       "7                  0.11510          NaN  \n",
       "8                  0.10720          NaN  \n",
       "9                  0.20750          NaN  \n",
       "\n",
       "[10 rows x 33 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data.csv')\n",
    "dataset.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to drop the last column of the dataframe as it has only 'NaN' as entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(columns = 'Unnamed: 32', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "            ...             radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           ...                    25.38          17.33           184.60   \n",
       "1           ...                    24.99          23.41           158.80   \n",
       "2           ...                    23.57          25.53           152.50   \n",
       "3           ...                    14.91          26.50            98.87   \n",
       "4           ...                    22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us look at what will constitute as features which will be the input layer of our neural network. Clearly the id of the patient should play no role in the diagnosis and we can ignore it for the rest of the discussion. The column diagnosis corresponds to the output of the the neural network which we will use for the purpose of training our neural network. We can now split our data into input (X) and output (y) components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(dataset)\n",
    "features = np.delete(features, [0,1])\n",
    "X = dataset.loc[:, features].values\n",
    "y = dataset.loc[:, 'diagnosis'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset a little preprocessing needs to be done in order to able to train the neural network. First we need to feature scale all the inputs. We will use a standard scaler in this case which basically converts all the inputs which has a zero mean and a unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc =  StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output vector y which is the diagnosis has two classes 'M' for malignant and 'B' for benign. We need to encode it into a numeric values such that our classifier can understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencode = LabelEncoder()\n",
    "y = labelencode.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data processed and ready, we are ready to build our classifier. We will be using Keras which is an API for packages for advanced machine learning like TensorFlow, Theano etc. We will be using the Keras API with the TensorFlow backend. As a first trial we will split the X and y data set into training and test set so that evaluate the performance of our neural network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will import all the libraries required to build our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(455, 30)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Sequential and Dense we will build our classifier and we will be able to add layers to our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "455/455 [==============================] - 0s - loss: 0.6902 - acc: 0.6374     \n",
      "Epoch 2/100\n",
      "455/455 [==============================] - 0s - loss: 0.6769 - acc: 0.6374     \n",
      "Epoch 3/100\n",
      "455/455 [==============================] - 0s - loss: 0.4298 - acc: 0.6374     \n",
      "Epoch 4/100\n",
      "455/455 [==============================] - 0s - loss: 0.3300 - acc: 0.6615     \n",
      "Epoch 5/100\n",
      "455/455 [==============================] - 0s - loss: 0.2823 - acc: 0.9758     \n",
      "Epoch 6/100\n",
      "455/455 [==============================] - 0s - loss: 0.2694 - acc: 0.9846     \n",
      "Epoch 7/100\n",
      "455/455 [==============================] - 0s - loss: 0.2040 - acc: 0.9890     \n",
      "Epoch 8/100\n",
      "455/455 [==============================] - 0s - loss: 0.1185 - acc: 0.9802     \n",
      "Epoch 9/100\n",
      "455/455 [==============================] - 0s - loss: 0.0781 - acc: 0.9890     \n",
      "Epoch 10/100\n",
      "455/455 [==============================] - 0s - loss: 0.0689 - acc: 0.9868     \n",
      "Epoch 11/100\n",
      "455/455 [==============================] - 0s - loss: 0.0767 - acc: 0.9868     \n",
      "Epoch 12/100\n",
      "455/455 [==============================] - 0s - loss: 0.0662 - acc: 0.9824     \n",
      "Epoch 13/100\n",
      "455/455 [==============================] - 0s - loss: 0.0563 - acc: 0.9890     \n",
      "Epoch 14/100\n",
      "455/455 [==============================] - 0s - loss: 0.0559 - acc: 0.9890     \n",
      "Epoch 15/100\n",
      "455/455 [==============================] - 0s - loss: 0.0607 - acc: 0.9868     \n",
      "Epoch 16/100\n",
      "455/455 [==============================] - 0s - loss: 0.0478 - acc: 0.9912     \n",
      "Epoch 17/100\n",
      "455/455 [==============================] - 0s - loss: 0.0471 - acc: 0.9890     \n",
      "Epoch 18/100\n",
      "455/455 [==============================] - 0s - loss: 0.0499 - acc: 0.9890     \n",
      "Epoch 19/100\n",
      "455/455 [==============================] - 0s - loss: 0.0412 - acc: 0.9912     \n",
      "Epoch 20/100\n",
      "455/455 [==============================] - 0s - loss: 0.0460 - acc: 0.9890     \n",
      "Epoch 21/100\n",
      "455/455 [==============================] - 0s - loss: 0.0443 - acc: 0.9912     \n",
      "Epoch 22/100\n",
      "455/455 [==============================] - 0s - loss: 0.0453 - acc: 0.9890     \n",
      "Epoch 23/100\n",
      "455/455 [==============================] - 0s - loss: 0.0405 - acc: 0.9912     \n",
      "Epoch 24/100\n",
      "455/455 [==============================] - 0s - loss: 0.0434 - acc: 0.9912     \n",
      "Epoch 25/100\n",
      "455/455 [==============================] - 0s - loss: 0.0395 - acc: 0.9912     \n",
      "Epoch 26/100\n",
      "455/455 [==============================] - 0s - loss: 0.0555 - acc: 0.9890     \n",
      "Epoch 27/100\n",
      "455/455 [==============================] - 0s - loss: 0.0518 - acc: 0.9868     \n",
      "Epoch 28/100\n",
      "455/455 [==============================] - 0s - loss: 0.0354 - acc: 0.9912     \n",
      "Epoch 29/100\n",
      "455/455 [==============================] - 0s - loss: 0.0410 - acc: 0.9890     \n",
      "Epoch 30/100\n",
      "455/455 [==============================] - 0s - loss: 0.0570 - acc: 0.9890     \n",
      "Epoch 31/100\n",
      "455/455 [==============================] - 0s - loss: 0.0654 - acc: 0.9758     \n",
      "Epoch 32/100\n",
      "455/455 [==============================] - 0s - loss: 0.0507 - acc: 0.9824     \n",
      "Epoch 33/100\n",
      "455/455 [==============================] - 0s - loss: 0.0456 - acc: 0.9890     \n",
      "Epoch 34/100\n",
      "455/455 [==============================] - 0s - loss: 0.0410 - acc: 0.9890     \n",
      "Epoch 35/100\n",
      "455/455 [==============================] - 0s - loss: 0.0413 - acc: 0.9890     \n",
      "Epoch 36/100\n",
      "455/455 [==============================] - 0s - loss: 0.0377 - acc: 0.9912     \n",
      "Epoch 37/100\n",
      "455/455 [==============================] - 0s - loss: 0.0375 - acc: 0.9890     \n",
      "Epoch 38/100\n",
      "455/455 [==============================] - 0s - loss: 0.0293 - acc: 0.9912     \n",
      "Epoch 39/100\n",
      "455/455 [==============================] - 0s - loss: 0.0417 - acc: 0.9890     \n",
      "Epoch 40/100\n",
      "455/455 [==============================] - 0s - loss: 0.0387 - acc: 0.9868     \n",
      "Epoch 41/100\n",
      "455/455 [==============================] - 0s - loss: 0.0350 - acc: 0.9912     \n",
      "Epoch 42/100\n",
      "455/455 [==============================] - 0s - loss: 0.0366 - acc: 0.9890     \n",
      "Epoch 43/100\n",
      "455/455 [==============================] - 0s - loss: 0.0358 - acc: 0.9912        \n",
      "Epoch 44/100\n",
      "455/455 [==============================] - 0s - loss: 0.0265 - acc: 0.9912        \n",
      "Epoch 45/100\n",
      "455/455 [==============================] - 0s - loss: 0.0357 - acc: 0.9890     \n",
      "Epoch 46/100\n",
      "455/455 [==============================] - 0s - loss: 0.0367 - acc: 0.9890     \n",
      "Epoch 47/100\n",
      "455/455 [==============================] - 0s - loss: 0.0283 - acc: 0.9934     \n",
      "Epoch 48/100\n",
      "455/455 [==============================] - 0s - loss: 0.0362 - acc: 0.9912     \n",
      "Epoch 49/100\n",
      "455/455 [==============================] - 0s - loss: 0.0314 - acc: 0.9912     \n",
      "Epoch 50/100\n",
      "455/455 [==============================] - 0s - loss: 0.0269 - acc: 0.9912     \n",
      "Epoch 51/100\n",
      "455/455 [==============================] - 0s - loss: 0.0253 - acc: 0.9912        \n",
      "Epoch 52/100\n",
      "455/455 [==============================] - 0s - loss: 0.0281 - acc: 0.9912        \n",
      "Epoch 53/100\n",
      "455/455 [==============================] - 0s - loss: 0.0624 - acc: 0.9802     \n",
      "Epoch 54/100\n",
      "455/455 [==============================] - 0s - loss: 0.1151 - acc: 0.9736     \n",
      "Epoch 55/100\n",
      "455/455 [==============================] - 0s - loss: 0.0578 - acc: 0.9802     \n",
      "Epoch 56/100\n",
      "455/455 [==============================] - 0s - loss: 0.0378 - acc: 0.9868     \n",
      "Epoch 57/100\n",
      "455/455 [==============================] - 0s - loss: 0.0378 - acc: 0.9868     \n",
      "Epoch 58/100\n",
      "455/455 [==============================] - 0s - loss: 0.0274 - acc: 0.9934     \n",
      "Epoch 59/100\n",
      "455/455 [==============================] - 0s - loss: 0.0342 - acc: 0.9890     \n",
      "Epoch 60/100\n",
      "455/455 [==============================] - 0s - loss: 0.0465 - acc: 0.9868     \n",
      "Epoch 61/100\n",
      "455/455 [==============================] - 0s - loss: 0.0428 - acc: 0.9868     \n",
      "Epoch 62/100\n",
      "455/455 [==============================] - 0s - loss: 0.0352 - acc: 0.9912        \n",
      "Epoch 63/100\n",
      "455/455 [==============================] - 0s - loss: 0.0327 - acc: 0.9868        \n",
      "Epoch 64/100\n",
      "455/455 [==============================] - 0s - loss: 0.0308 - acc: 0.9912     \n",
      "Epoch 65/100\n",
      "455/455 [==============================] - 0s - loss: 0.0288 - acc: 0.9912     \n",
      "Epoch 66/100\n",
      "455/455 [==============================] - 0s - loss: 0.0258 - acc: 0.9912     \n",
      "Epoch 67/100\n",
      "455/455 [==============================] - 0s - loss: 0.0214 - acc: 0.9934        \n",
      "Epoch 68/100\n",
      "455/455 [==============================] - 0s - loss: 0.0221 - acc: 0.9912        \n",
      "Epoch 69/100\n",
      "455/455 [==============================] - 0s - loss: 0.0210 - acc: 0.9934        \n",
      "Epoch 70/100\n",
      "455/455 [==============================] - 0s - loss: 0.0221 - acc: 0.9912     \n",
      "Epoch 71/100\n",
      "455/455 [==============================] - 0s - loss: 0.0092 - acc: 0.9978     \n",
      "Epoch 72/100\n",
      "455/455 [==============================] - 0s - loss: 0.0237 - acc: 0.9934        \n",
      "Epoch 73/100\n",
      "455/455 [==============================] - 0s - loss: 0.0139 - acc: 0.9956     \n",
      "Epoch 74/100\n",
      "455/455 [==============================] - 0s - loss: 0.0096 - acc: 0.9978     \n",
      "Epoch 75/100\n",
      "455/455 [==============================] - 0s - loss: 0.0110 - acc: 0.9956     \n",
      "Epoch 76/100\n",
      "455/455 [==============================] - 0s - loss: 0.0241 - acc: 0.9956     \n",
      "Epoch 77/100\n",
      "455/455 [==============================] - 0s - loss: 0.0141 - acc: 0.9978        \n",
      "Epoch 78/100\n",
      "455/455 [==============================] - 0s - loss: 0.0113 - acc: 0.9956     \n",
      "Epoch 79/100\n",
      "455/455 [==============================] - 0s - loss: 0.0071 - acc: 1.0000     \n",
      "Epoch 80/100\n",
      "455/455 [==============================] - 0s - loss: 0.0142 - acc: 0.9978     \n",
      "Epoch 81/100\n",
      "455/455 [==============================] - 0s - loss: 0.0044 - acc: 1.0000        \n",
      "Epoch 82/100\n",
      "455/455 [==============================] - 0s - loss: 0.0238 - acc: 0.9912     \n",
      "Epoch 83/100\n",
      "455/455 [==============================] - 0s - loss: 0.0282 - acc: 0.9912     \n",
      "Epoch 84/100\n",
      "455/455 [==============================] - 0s - loss: 0.0542 - acc: 0.9912        \n",
      "Epoch 85/100\n",
      "455/455 [==============================] - 0s - loss: 0.0377 - acc: 0.9912        \n",
      "Epoch 86/100\n",
      "455/455 [==============================] - 0s - loss: 0.0139 - acc: 0.9956     \n",
      "Epoch 87/100\n",
      "455/455 [==============================] - 0s - loss: 0.0138 - acc: 0.9956        \n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s - loss: 0.0131 - acc: 0.9956        \n",
      "Epoch 89/100\n",
      "455/455 [==============================] - 0s - loss: 0.0081 - acc: 0.9978     \n",
      "Epoch 90/100\n",
      "455/455 [==============================] - 0s - loss: 0.0290 - acc: 0.9934     \n",
      "Epoch 91/100\n",
      "455/455 [==============================] - 0s - loss: 0.0085 - acc: 0.9978     \n",
      "Epoch 92/100\n",
      "455/455 [==============================] - 0s - loss: 0.0094 - acc: 0.9978     \n",
      "Epoch 93/100\n",
      "455/455 [==============================] - 0s - loss: 0.0060 - acc: 0.9978        \n",
      "Epoch 94/100\n",
      "455/455 [==============================] - 0s - loss: 0.0125 - acc: 0.9978        \n",
      "Epoch 95/100\n",
      "455/455 [==============================] - 0s - loss: 0.0118 - acc: 0.9956        \n",
      "Epoch 96/100\n",
      "455/455 [==============================] - 0s - loss: 0.0128 - acc: 0.9956     \n",
      "Epoch 97/100\n",
      "455/455 [==============================] - 0s - loss: 0.0123 - acc: 0.9956     \n",
      "Epoch 98/100\n",
      "455/455 [==============================] - 0s - loss: 0.0094 - acc: 0.9978     \n",
      "Epoch 99/100\n",
      "455/455 [==============================] - 0s - loss: 0.0034 - acc: 1.0000     \n",
      "Epoch 100/100\n",
      "455/455 [==============================] - 0s - loss: 0.0025 - acc: 1.0000        \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f94e89fec50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = Sequential()\n",
    "\n",
    "#Add the input layer and first hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu', input_dim = 30)  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "#Add second hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu')  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "#Add third hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu')  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "#Add fourth hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu')  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "#Add fifth hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu')  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "#Add sixth hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu')  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "#Add seventh hidden layer\n",
    "classifier.add(Dense(units = 15, kernel_initializer = 'uniform', activation = 'relu')  )\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "\n",
    "#Add eighth hidden layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid')  )\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classifier seems to have a really good accuracy on the training set. But that might be just because of overfitting. The Dropout is used as a form of regularization while training our classifier. However in order to know the actual accuracy of our classifier we need to implement on the test set and how well our classifier performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is :  0.964912280702\n"
     ]
    }
   ],
   "source": [
    "accuracy_cm = (cm[0, 0] + cm[1, 1])/(sum(sum(cm)))\n",
    "print('The accuracy is : ', accuracy_cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not bad, our algorithm is able to distinguish between malignant and benign tumors with an accuracy of nearly 96.5%. Remember this dataset is not large but with the extensive number of features and a deep artificial neural network, we are able to make a very good prediction. We still have nearly 3.5% chance of getting it wrong. There also seems to be a difference between the accuracy on the training set and that on the test set. We would also like to close that divide if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
